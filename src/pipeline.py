import pandas as pd
import os
import sys

# Import c√°c module ƒë√£ x√¢y d·ª±ng
# (ƒê·∫£m b·∫£o file __init__.py ƒë√£ c√≥ trong th∆∞ m·ª•c src ƒë·ªÉ Python hi·ªÉu ƒë√¢y l√† package)
try:
    from src.preprocessor import DataPreprocessor
    from src.segmenter import DataSegmenter
    from src.topic_classifier import TopicClassifier
    from src.scorer import SentimentScorer
except ModuleNotFoundError:
    # Fallback cho tr∆∞·ªùng h·ª£p ch·∫°y tr·ª±c ti·∫øp file n√†y m√† kh√¥ng qua module context
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
    from src.preprocessor import DataPreprocessor
    from src.segmenter import DataSegmenter
    from src.topic_classifier import TopicClassifier
    from src.scorer import SentimentScorer

class SentimentPipeline:
    def __init__(self, resource_path='resources'):
        """
        Kh·ªüi t·∫°o d√¢y chuy·ªÅn: Tuy·ªÉn d·ª•ng 4 c√¥ng nh√¢n v√† ph√°t c√¥ng c·ª• (Dictionary/Config)
        """
        print("‚öôÔ∏è  ƒêang kh·ªüi ƒë·ªông Sentiment Pipeline...")
        self.dict_path = f"{resource_path}/dictionaries"
        self.config_path = resource_path
        
        # 1. C√¥ng nh√¢n L√†m s·∫°ch (Giai ƒëo·∫°n 2)
        self.preprocessor = DataPreprocessor(dict_path=self.dict_path)
        
        # 2. C√¥ng nh√¢n C·∫Øt c√¢u (Giai ƒëo·∫°n 3.1)
        self.segmenter = DataSegmenter(dict_path=self.dict_path)
        
        # 3. C√¥ng nh√¢n Ph√¢n lo·∫°i Ch·ªß ƒë·ªÅ (Giai ƒëo·∫°n 3.2)
        self.classifier = TopicClassifier(dict_path=self.dict_path)
        
        # 4. C√¥ng nh√¢n Ch·∫•m ƒëi·ªÉm (Giai ƒëo·∫°n 3.3)
        self.scorer = SentimentScorer(resource_path=self.config_path)
        
        print("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")

    def process_file(self, input_path, output_path):
        """
        H√†m ch·∫°y to√†n b·ªô quy tr√¨nh t·ª´ A-Z
        """
        # --- B∆Ø·ªöC 0: KI·ªÇM TRA ƒê·∫¶U V√ÄO ---
        if not os.path.exists(input_path):
            print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file ƒë·∫ßu v√†o t·∫°i {input_path}")
            return None

        try:
            print(f"\nüöÄ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù FILE: {input_path}")
            
            # ƒê·ªçc d·ªØ li·ªáu th√¥
            df = pd.read_csv(input_path, encoding='utf-8-sig')
            print(f"üìÇ ƒê√£ n·∫°p {len(df)} d√≤ng d·ªØ li·ªáu th√¥.")

            # --- B∆Ø·ªöC 1: L√ÄM S·∫†CH (PREPROCESSING) ---
            # Input: Raw Text -> Output: Processed Text, Masked Info
            df_clean = self.preprocessor.run(df)

            # --- B∆Ø·ªöC 2: T√ÅCH C√ÇU (SEGMENTATION) ---
            # Input: 1 d√≤ng -> Output: N d√≤ng (n·∫øu c√≥ t·ª´ 'nh∆∞ng')
            df_segmented = self.segmenter.run(df_clean)

            # --- B∆Ø·ªöC 3: PH√ÇN LO·∫†I CH·ª¶ ƒê·ªÄ (TOPIC) ---
            # Input: Segment Content -> Output: Topic Code
            df_classified = self.classifier.run(df_segmented)

            # --- B∆Ø·ªöC 4: CH·∫§M ƒêI·ªÇM & LOGIC M√ÇU THU·∫™N (SCORING) ---
            # Input: Text + Reaction -> Output: Score, Label, Priority
            df_final = self.scorer.run(df_classified)

            # --- B∆Ø·ªöC 5: L∆ØU K·∫æT QU·∫¢ ---
            # T·∫°o th∆∞ m·ª•c output n·∫øu ch∆∞a c√≥
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # Ch·ªçn c√°c c·ªôt quan tr·ªçng ƒë·ªÉ xu·∫•t (cho file g·ªçn nh·∫π h∆°n)
            # Ho·∫∑c xu·∫•t t·∫•t c·∫£ (df_final) n·∫øu mu·ªën debug
            output_columns = [
                'record_id', 'segment_id', 'social_user_id', 'timestamp',
                'segment_content', 'topic_code', 'reaction_label',
                'text_score', 'reaction_score', 'final_score', 
                'sentiment_label', 'priority_level', 'is_split', 'source_channel'
            ]
            
            # Ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt c√≥ trong DataFrame (ph√≤ng tr∆∞·ªùng h·ª£p l·ªói t√™n c·ªôt)
            final_cols = [c for c in output_columns if c in df_final.columns]
            
            df_final[final_cols].to_csv(output_path, index=False, encoding='utf-8-sig')
            
            print(f"\n‚úÖ QUY TR√åNH HO√ÄN T·∫§T TH√ÄNH C√îNG!")
            print(f"üíæ K·∫øt qu·∫£ cu·ªëi c√πng l∆∞u t·∫°i: {output_path}")
            print("-" * 50)
            
            return df_final

        except Exception as e:
            print(f"\n‚ùå C√ì L·ªñI X·∫¢Y RA TRONG PIPELINE: {e}")
            import traceback
            traceback.print_exc()
            return None

# --- MAIN ENTRY POINT (Ch·∫°y tr·ª±c ti·∫øp file n√†y) ---
if __name__ == "__main__":
    # C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n
    INPUT_FILE = 'data/raw/raw_comments.csv'
    OUTPUT_FILE = 'data/output/SCORED_FEEDBACK_FINAL.csv'
    
    # Kh·ªüi t·∫°o Pipeline
    pipeline = SentimentPipeline(resource_path='resources')
    
    # Ch·∫°y
    pipeline.process_file(INPUT_FILE, OUTPUT_FILE)