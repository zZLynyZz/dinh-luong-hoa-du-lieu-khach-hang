import pandas as pd
import os
import sys
from datetime import datetime

current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir) 
if project_root not in sys.path:
    sys.path.append(project_root)

from src.utils import ConfigLoader 

# ==============================================================================
# C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N
# ==============================================================================
BASE_DIR = project_root 
INPUT_CRAWLER_DIR = os.path.join(BASE_DIR, 'data', 'crawler')
OUTPUT_RAW_DIR = os.path.join(BASE_DIR, 'data', 'raw')

FILE_POSTS = 'posts_detail.csv'
FILE_COMMENTS = 'comments_detail.csv'
FILE_REACTIONS = 'reactions_detail.csv'
FILE_OUTPUT_MASTER = 'raw_fb_data.csv'

class DataMerger:
    def __init__(self):
        self.posts_path = os.path.join(INPUT_CRAWLER_DIR, FILE_POSTS)
        self.comments_path = os.path.join(INPUT_CRAWLER_DIR, FILE_COMMENTS)
        self.reactions_path = os.path.join(INPUT_CRAWLER_DIR, FILE_REACTIONS)
        self.output_path = os.path.join(OUTPUT_RAW_DIR, FILE_OUTPUT_MASTER)

        # Load ConfigLoader
        self.app_config = ConfigLoader.load()
        self.reaction_map = getattr(self.app_config, 'reaction_map', {})
        if not self.reaction_map:
            print("‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y 'reaction_map' trong ConfigLoader.")

    def load_csv(self, file_path):
        if os.path.exists(file_path):
            try:
                return pd.read_csv(file_path, encoding='utf-8-sig')
            except:
                return pd.DataFrame()
        return pd.DataFrame()

    def normalize_reaction(self, raw_react):
        if pd.isna(raw_react) or raw_react == "":
            return "NONE"
        clean_key = str(raw_react).strip().lower()
        return self.reaction_map.get(clean_key, "NONE")

    def run_merge(self):
        print("üîÑ [MERGER] B·∫ÆT ƒê·∫¶U GH√âP N·ªêI & CHU·∫®N H√ìA...")
        
        # 1. ƒê·ªçc d·ªØ li·ªáu
        df_posts = self.load_csv(self.posts_path)
        df_comments = self.load_csv(self.comments_path)
        df_reactions = self.load_csv(self.reactions_path)

        if df_posts.empty:
            print("‚ùå [MERGER] Thi·∫øu file POSTS.")
            return

        # X√°c ƒë·ªãnh Admin ƒë·ªÉ l·ªçc (ng∆∞·ªùi ƒëƒÉng b√†i)
        admin_ids = set(df_posts['user_id'].astype(str).unique())
        print(f"   üõ°Ô∏è ƒê√£ x√°c ƒë·ªãnh {len(admin_ids)} Admin ID c·∫ßn l·ªçc.")

        post_context_map = dict(zip(df_posts['post_id'].astype(str), df_posts['context_content']))
        
        merged_records = []
        processed_interactions = set()

        # --- X·ª¨ L√ù COMMENT ---
        if not df_comments.empty:
            skipped_admin = 0
            print(f"   ‚Ü≥ ƒêang qu√©t {len(df_comments)} comments...")
            
            for _, row in df_comments.iterrows():
                post_id = str(row.get('post_id', ''))
                user_id = str(row.get('user_id', ''))
                
                # [L·ªåC ADMIN COMMENT]
                if user_id in admin_ids:
                    skipped_admin += 1
                    continue 

                raw_reaction = "NONE"
                if not df_reactions.empty:
                    react_rows = df_reactions[
                        (df_reactions['post_id'].astype(str) == post_id) & 
                        (df_reactions['user_id'].astype(str) == user_id)
                    ]
                    if not react_rows.empty:
                        raw_reaction = react_rows.iloc[0]['reaction_type']

                # L·∫•y Timestamp
                cmt_time = row.get('timestamp', row.get('time', None))
                if pd.isna(cmt_time) or cmt_time == "":
                    final_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                else:
                    final_time = cmt_time

                merged_records.append({
                    'timestamp': final_time,
                    'social_user_id': user_id,
                    'source_channel': 'Fanpage_Comment',
                    'original_text': row.get('original_text', ''),
                    'reaction_label': self.normalize_reaction(raw_reaction),
                    'context_content': None
                })
                processed_interactions.add((post_id, user_id))
            
            if skipped_admin > 0:
                print(f"     üö´ ƒê√£ l·ªçc b·ªè {skipped_admin} comment c·ªßa Admin.")

        # --- X·ª¨ L√ù REACTION L·∫∫ ---
        if not df_reactions.empty:
            skipped_admin_react = 0
            print(f"   ‚Ü≥ ƒêang qu√©t {len(df_reactions)} reactions l·∫ª...")
            
            for _, row in df_reactions.iterrows():
                post_id = str(row.get('post_id', ''))
                user_id = str(row.get('user_id', ''))

                # [L·ªåC ADMIN REACTION]
                if user_id in admin_ids:
                    skipped_admin_react += 1
                    continue

                if (post_id, user_id) not in processed_interactions:
                    context_text = post_context_map.get(post_id, None)
                    if context_text:
                        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                        merged_records.append({
                            'timestamp': current_time, 
                            'social_user_id': user_id,
                            'source_channel': 'Fanpage_Post_Reaction',
                            'original_text': None,
                            'reaction_label': self.normalize_reaction(row.get('reaction_type', 'NONE')),
                            'context_content': context_text
                        })
            
            # [M·ªöI] Th√™m d√≤ng n√†y ƒë·ªÉ th√¥ng b√°o s·ªë l∆∞·ª£ng b·ªã l·ªçc
            if skipped_admin_react > 0:
                print(f"     üö´ ƒê√£ l·ªçc b·ªè {skipped_admin_react} reaction l·∫ª c·ªßa Admin.")

        # --- L∆ØU FILE ---
        if merged_records:
            df_final = pd.DataFrame(merged_records)
            df_final.insert(0, 'record_id', [f"REC_{i+1:03d}" for i in range(len(df_final))])
            
            cols = ['record_id', 'timestamp', 'social_user_id', 'source_channel', 
                    'original_text', 'reaction_label', 'context_content']
            df_final = df_final.reindex(columns=cols)

            os.makedirs(OUTPUT_RAW_DIR, exist_ok=True)
            df_final.to_csv(self.output_path, index=False, encoding='utf-8-sig')
            print(f"‚úÖ [MERGER] Th√†nh c√¥ng! File: {self.output_path}")
            print(f"üìä T·ªïng s·ªë: {len(df_final)} d√≤ng.")
        else:
            print("‚ö†Ô∏è [MERGER] Kh√¥ng c√≥ d·ªØ li·ªáu.")

if __name__ == "__main__":
    merger = DataMerger()
    merger.run_merge()  