import os
import sys
import time
import asyncio # üëà Th√™m th∆∞ vi·ªán n√†y ƒë·ªÉ ch·∫°y Async

# ==============================================================================
# [C·∫§U H√åNH ƒê·∫¶U V√ÄO] - B·∫†N CH·ªàNH S·ª¨A LINK PAGE ·ªû ƒê√ÇY
# ==============================================================================
TARGET_PAGE_URL = 'https://www.facebook.com/tikopapp' 

# S·ªë l∆∞·ª£ng b√†i vi·∫øt mu·ªën l·∫•y
NUM_POSTS_TO_CRAWL = 10 

# ==============================================================================
# C·∫§U H√åNH H·ªÜ TH·ªêNG
# ==============================================================================
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

# Import Modules
from src import CrawlerManager, DataMerger, DataProcessor, SentimentScorer

def print_separator(step_name):
    print("\n" + "="*60)
    print(f"üöÄ B·∫ÆT ƒê·∫¶U GIAI ƒêO·∫†N: {step_name.upper()}")
    print("="*60)

def main():

    total_start = time.time()
    print(f"üïí Engine kh·ªüi ƒë·ªông l√∫c: {time.ctime(total_start)}")
    print(f"üéØ M·ª•c ti√™u: {TARGET_PAGE_URL} | S·ªë l∆∞·ª£ng: {NUM_POSTS_TO_CRAWL} b√†i")

    # --------------------------------------------------------------------------
    # PHASE 1: CRAWLING 
    # --------------------------------------------------------------------------
    # L∆∞u √Ω: N·∫øu b·∫°n ƒë√£ c√≥ d·ªØ li·ªáu s·∫µn trong data/crawler v√† kh√¥ng mu·ªën c√†o l·∫°i
    # th√¨ c√≥ th·ªÉ comment (ƒë√≥ng bƒÉng) ƒëo·∫°n n√†y l·∫°i.
    
    print_separator("1. CRAWLING DATA")
    try:
        # 1. Truy·ªÅn tham s·ªë ngay l√∫c kh·ªüi t·∫°o class
        crawler = CrawlerManager(target_url=TARGET_PAGE_URL, max_posts=NUM_POSTS_TO_CRAWL)
        
        # 2. D√πng asyncio.run() v√¨ h√†m run_full_crawl l√† async
        asyncio.run(crawler.run_full_crawl())
            
    except Exception as e:
        print(f"‚ö†Ô∏è B·ªè qua b∆∞·ªõc Crawler ho·∫∑c c√≥ l·ªói: {e}")
        print("üëâ Ti·∫øp t·ª•c x·ª≠ l√Ω d·ªØ li·ªáu ƒëang c√≥ s·∫µn trong data/crawler...")

    # --------------------------------------------------------------------------
    # PHASE 2: MERGING
    # --------------------------------------------------------------------------
    print_separator("2. MERGING RAW DATA")
    try:
        merger = DataMerger()
        merger.run_merge()
    except Exception as e:
        print(f"‚ùå L·ªói b∆∞·ªõc Merge: {e}")
        return 

    # --------------------------------------------------------------------------
    # PHASE 3: PROCESSING
    # --------------------------------------------------------------------------
    print_separator("3. PROCESSING DATA")
    try:
        processor = DataProcessor()
        processor.run_process()
    except Exception as e:
        print(f"‚ùå L·ªói b∆∞·ªõc Processing: {e}")
        return

    # --------------------------------------------------------------------------
    # PHASE 4: SCORING
    # --------------------------------------------------------------------------
    print_separator("4. SENTIMENT SCORING")
    try:
        scorer = SentimentScorer()
        scorer.run_analysis()
    except Exception as e:
        print(f"‚ùå L·ªói b∆∞·ªõc Scoring: {e}")
        return

    # --------------------------------------------------------------------------
    # K·∫æT TH√öC
    # --------------------------------------------------------------------------
    total_end = time.time()
    duration = total_end - total_start
    print("\n" + "="*60)
    print(f"‚úÖ HO√ÄN T·∫§T TO√ÄN B·ªò QUY TR√åNH!")
    print(f"‚è±Ô∏è T·ªïng th·ªùi gian: {duration:.2f} gi√¢y")
    print("="*60)
    print("üìÇ Xem b√°o c√°o t·∫°i: data/reports/final_sentiment_report.csv")

if __name__ == "__main__":
    main()